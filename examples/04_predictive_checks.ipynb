{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da1ed8cf",
   "metadata": {},
   "source": [
    "# Posterior Predictive Checks for State Space Models\n",
    "\n",
    "This notebook introduces **posterior predictive checks**, an advanced diagnostic that asks: \"If the model were true, how likely is the observed data?\" This provides a complementary view to the state-likelihood consistency checks.\n",
    "\n",
    "**Learning objectives:**\n",
    "- Understand predictive density and its computation\n",
    "- Learn when to use log-space for numerical stability\n",
    "- Compute posterior predictive p-values\n",
    "- Interpret p-value patterns for model diagnostics\n",
    "- Combine multiple diagnostic approaches\n",
    "\n",
    "**Previous:** [03_time_resolved_diagnostics.ipynb](03_time_resolved_diagnostics.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90722a45",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b18f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "from utils import configure_notebook_plotting\n",
    "\n",
    "from statespacecheck import (\n",
    "    log_predictive_density,\n",
    "    predictive_density,\n",
    "    predictive_pvalue,\n",
    ")\n",
    "\n",
    "configure_notebook_plotting()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbf209a",
   "metadata": {},
   "source": [
    "## What is Predictive Density?\n",
    "\n",
    "**Predictive density** measures how likely the observed data is under the model's prediction:\n",
    "\n",
    "$$p(y_t) = \\int p(y_t | x_t) p(x_t | y_{1:t-1}) dx_t = \\sum_x p(y_t | x_t) p(x_t)$$\n",
    "\n",
    "**Components:**\n",
    "- $p(y_t | x_t)$: Observation likelihood (how likely is this observation at each state?)\n",
    "- $p(x_t)$: State distribution (what states are probable?)\n",
    "- Integration: Average likelihood over all probable states\n",
    "\n",
    "**Interpretation:**\n",
    "- **High predictive density**: Data is consistent with model predictions\n",
    "- **Low predictive density**: Data is surprising given the model\n",
    "- Averaged over time, gives overall model fit\n",
    "\n",
    "**Key difference from previous metrics:**\n",
    "- KL/overlap: Compare distributions (state vs likelihood)\n",
    "- Predictive density: Evaluate data plausibility under the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2036aa",
   "metadata": {},
   "source": [
    "## Computing Predictive Density\n",
    "\n",
    "Let's start with a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430519d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate simple data\n",
    "position_bins = np.linspace(0, 100, 50)\n",
    "\n",
    "# State distribution: Model expects position around 50 cm\n",
    "state_dist = norm.pdf(position_bins, loc=50.0, scale=5.0)\n",
    "state_dist = state_dist / state_dist.sum()  # Normalize\n",
    "\n",
    "# Likelihood: Observation suggests position around 52 cm (close to prediction)\n",
    "likelihood = norm.pdf(position_bins, loc=52.0, scale=3.0)\n",
    "# NOTE: likelihood is NOT normalized - it's p(y|x) evaluated at each x\n",
    "\n",
    "# Add time dimension\n",
    "state_dist_2d = state_dist[np.newaxis, :]\n",
    "likelihood_2d = likelihood[np.newaxis, :]\n",
    "\n",
    "# Compute predictive density\n",
    "pred_dens = predictive_density(state_dist_2d, likelihood_2d)[0]\n",
    "\n",
    "print(f\"Predictive density: {pred_dens:.6f}\")\n",
    "print(f\"\\nInterpretation: The observed data has predictive density {pred_dens:.6f}\")\n",
    "print(\"This value depends on the bin size and normalization.\")\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(position_bins, state_dist, linewidth=2.5, color=\"#1f77b4\", label=\"State distribution p(x)\")\n",
    "ax.plot(\n",
    "    position_bins,\n",
    "    likelihood,\n",
    "    linewidth=2.5,\n",
    "    color=\"#ff7f0e\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"Likelihood p(y|x)\",\n",
    ")\n",
    "ax.fill_between(position_bins, state_dist, alpha=0.3, color=\"#1f77b4\")\n",
    "ax.fill_between(position_bins, likelihood, alpha=0.3, color=\"#ff7f0e\")\n",
    "ax.axvline(50, color=\"#1f77b4\", linestyle=\":\", alpha=0.5, label=\"State mean\")\n",
    "ax.axvline(52, color=\"#ff7f0e\", linestyle=\":\", alpha=0.5, label=\"Likelihood mean\")\n",
    "ax.set_xlabel(\"Position (cm)\")\n",
    "ax.set_ylabel(\"Probability Density\")\n",
    "ax.set_title(f\"Predictive Density Computation (p(y) = {pred_dens:.6f})\")\n",
    "ax.legend(frameon=True, loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7aaab5",
   "metadata": {},
   "source": [
    "### Understanding the Computation\n",
    "\n",
    "The predictive density integrates (sums) the product of:\n",
    "1. **State distribution**: Probability of each position\n",
    "2. **Likelihood**: How well the data fits at each position\n",
    "\n",
    "When state and likelihood agree (both peak near the same location), predictive density is high. When they disagree, predictive density is low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1cdbf0",
   "metadata": {},
   "source": [
    "## Comparing Good vs Poor Fit\n",
    "\n",
    "Let's compare predictive density for well-fitting vs poorly-fitting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1db3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1: Good fit - likelihood agrees with state\n",
    "likelihood_good = norm.pdf(position_bins, loc=50.0, scale=3.0)  # Same location as state\n",
    "likelihood_good_2d = likelihood_good[np.newaxis, :]\n",
    "pred_dens_good = predictive_density(state_dist_2d, likelihood_good_2d)[0]\n",
    "\n",
    "# Case 2: Poor fit - likelihood disagrees with state\n",
    "likelihood_poor = norm.pdf(position_bins, loc=80.0, scale=3.0)  # Far from state\n",
    "likelihood_poor_2d = likelihood_poor[np.newaxis, :]\n",
    "pred_dens_poor = predictive_density(state_dist_2d, likelihood_poor_2d)[0]\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Good fit\n",
    "ax1.plot(position_bins, state_dist, linewidth=2.5, color=\"#1f77b4\", label=\"State dist\")\n",
    "ax1.plot(\n",
    "    position_bins,\n",
    "    likelihood_good,\n",
    "    linewidth=2.5,\n",
    "    color=\"#2ca02c\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"Likelihood\",\n",
    ")\n",
    "ax1.fill_between(position_bins, state_dist, alpha=0.3, color=\"#1f77b4\")\n",
    "ax1.fill_between(position_bins, likelihood_good, alpha=0.3, color=\"#2ca02c\")\n",
    "ax1.set_xlabel(\"Position (cm)\")\n",
    "ax1.set_ylabel(\"Density\")\n",
    "ax1.set_title(f\"Good Fit: p(y) = {pred_dens_good:.6f}\")\n",
    "ax1.legend(frameon=True, loc=\"upper right\")\n",
    "\n",
    "# Poor fit\n",
    "ax2.plot(position_bins, state_dist, linewidth=2.5, color=\"#1f77b4\", label=\"State dist\")\n",
    "ax2.plot(\n",
    "    position_bins,\n",
    "    likelihood_poor,\n",
    "    linewidth=2.5,\n",
    "    color=\"#d62728\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"Likelihood\",\n",
    ")\n",
    "ax2.fill_between(position_bins, state_dist, alpha=0.3, color=\"#1f77b4\")\n",
    "ax2.fill_between(position_bins, likelihood_poor, alpha=0.3, color=\"#d62728\")\n",
    "ax2.set_xlabel(\"Position (cm)\")\n",
    "ax2.set_ylabel(\"Density\")\n",
    "ax2.set_title(f\"Poor Fit: p(y) = {pred_dens_poor:.6f}\")\n",
    "ax2.legend(frameon=True, loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Predictive density comparison:\")\n",
    "print(f\"  Good fit: {pred_dens_good:.6f}\")\n",
    "print(f\"  Poor fit: {pred_dens_poor:.6f}\")\n",
    "print(f\"  Ratio: {pred_dens_good / pred_dens_poor:.1f}x higher for good fit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9337e8",
   "metadata": {},
   "source": [
    "The predictive density is much higher when state and likelihood agree! This quantifies how \"surprising\" the data is under the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe10f21",
   "metadata": {},
   "source": [
    "## Log Predictive Density for Numerical Stability\n",
    "\n",
    "For real applications with many bins or peaked distributions, predictive densities can become very small, leading to numerical underflow. We use **log-space** computation for stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec18e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate numerical issues with many bins\n",
    "position_bins_fine = np.linspace(0, 100, 500)  # Many bins!\n",
    "\n",
    "state_fine = norm.pdf(position_bins_fine, loc=50.0, scale=5.0)\n",
    "state_fine = state_fine / state_fine.sum()\n",
    "likelihood_fine = norm.pdf(position_bins_fine, loc=50.0, scale=3.0)\n",
    "\n",
    "state_fine_2d = state_fine[np.newaxis, :]\n",
    "likelihood_fine_2d = likelihood_fine[np.newaxis, :]\n",
    "\n",
    "# Linear space computation\n",
    "pred_dens_linear = predictive_density(state_fine_2d, likelihood_fine_2d)[0]\n",
    "\n",
    "# Log space computation\n",
    "log_pred_dens = log_predictive_density(state_fine_2d, likelihood=likelihood_fine_2d)[0]\n",
    "\n",
    "print(f\"Linear space: p(y) = {pred_dens_linear:.10f}\")\n",
    "print(f\"Log space: log p(y) = {log_pred_dens:.6f}\")\n",
    "print(f\"Verification: exp(log p(y)) = {np.exp(log_pred_dens):.10f}\")\n",
    "print(\"\\nLog space is more numerically stable for small probabilities!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b50fba",
   "metadata": {},
   "source": [
    "**Why use log-space?**\n",
    "- Prevents underflow for very small probabilities\n",
    "- More numerically stable for optimization\n",
    "- Standard practice in Bayesian inference\n",
    "- Can directly use log-likelihoods without exp/log round-trip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f474d000",
   "metadata": {},
   "source": [
    "## Posterior Predictive P-Values\n",
    "\n",
    "A single predictive density value is hard to interpret (\"Is 0.0023 good or bad?\"). **Posterior predictive p-values** provide context by comparing to simulated data:\n",
    "\n",
    "**Process:**\n",
    "1. Compute predictive density for observed data\n",
    "2. Generate many datasets from the model\n",
    "3. Compute predictive density for each simulated dataset\n",
    "4. P-value = proportion of simulated densities ≥ observed density\n",
    "\n",
    "**Interpretation:**\n",
    "- **p ≈ 0.5**: Observed data is typical for this model\n",
    "- **p ≈ 0 or 1**: Observed data is extreme (model may be misspecified)\n",
    "- **Systematic patterns**: Indicate model problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3806825",
   "metadata": {},
   "source": [
    "### Example: Computing P-Values\n",
    "\n",
    "Let's create a simple scenario and compute p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfdd9b1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Generate time series data\n",
    "np.random.seed(42)\n",
    "n_time = 100\n",
    "\n",
    "# True model: position follows Gaussian with some dynamics\n",
    "true_means = 50 + 10 * np.sin(2 * np.pi * np.arange(n_time) / 50)\n",
    "state_dist_seq = np.array([norm.pdf(position_bins, loc=m, scale=5.0) for m in true_means])\n",
    "state_dist_seq = state_dist_seq / state_dist_seq.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Observed likelihood: mostly consistent with model\n",
    "observed_likelihood = np.array(\n",
    "    [norm.pdf(position_bins, loc=m + np.random.normal(0, 2), scale=3.0) for m in true_means]\n",
    ")\n",
    "\n",
    "# Compute observed log predictive density\n",
    "observed_log_pred = log_predictive_density(state_dist_seq, likelihood=observed_likelihood)\n",
    "\n",
    "print(\"Observed log predictive densities (first 5 time points):\")\n",
    "print(observed_log_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e16a853",
   "metadata": {},
   "source": [
    "Now let's create a sampler that generates datasets from the model and compute their predictive densities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50edda7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sampler(state_dist_seq, true_means, position_bins):\n",
    "    \"\"\"Create a function that samples predictive densities from the model.\"\"\"\n",
    "    rng = np.random.default_rng(42)  # Fixed seed for reproducibility\n",
    "\n",
    "    def sampler(n_samples):\n",
    "        \"\"\"Sample n predictive density realizations from the model.\"\"\"\n",
    "        log_pred_samples = np.zeros((n_samples, len(true_means)))\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            # Simulate likelihood from the model\n",
    "            sim_likelihood = np.array(\n",
    "                [norm.pdf(position_bins, loc=m + rng.normal(0, 2), scale=3.0) for m in true_means]\n",
    "            )\n",
    "\n",
    "            # Compute predictive density for this simulation\n",
    "            log_pred_samples[i] = log_predictive_density(state_dist_seq, likelihood=sim_likelihood)\n",
    "\n",
    "        return log_pred_samples\n",
    "\n",
    "    return sampler\n",
    "\n",
    "\n",
    "# Create sampler\n",
    "sampler = create_sampler(state_dist_seq, true_means, position_bins)\n",
    "\n",
    "# Compute p-values\n",
    "p_values = predictive_pvalue(observed_log_pred, sampler, n_samples=1000)\n",
    "\n",
    "print(\"\\nP-values (first 10 time points):\")\n",
    "print(p_values[:10])\n",
    "print(\"\\nP-value statistics:\")\n",
    "print(f\"  Mean: {np.mean(p_values):.3f}\")\n",
    "print(f\"  Std: {np.std(p_values):.3f}\")\n",
    "print(f\"  Min: {np.min(p_values):.3f}\")\n",
    "print(f\"  Max: {np.max(p_values):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9426fe80",
   "metadata": {},
   "source": [
    "For a well-specified model, p-values should be approximately uniformly distributed between 0 and 1. Let's visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ce2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Time series of p-values\n",
    "ax1.plot(\n",
    "    np.arange(n_time), p_values, linewidth=2, marker=\"o\", markersize=4, alpha=0.7, color=\"#1f77b4\"\n",
    ")\n",
    "ax1.axhline(0.5, color=\"green\", linestyle=\"--\", alpha=0.5, linewidth=2, label=\"Expected mean\")\n",
    "ax1.fill_between(np.arange(n_time), 0.05, 0.95, alpha=0.2, color=\"green\", label=\"90% range\")\n",
    "ax1.set_xlabel(\"Time\")\n",
    "ax1.set_ylabel(\"P-value\")\n",
    "ax1.set_title(\"Posterior Predictive P-values Over Time\")\n",
    "ax1.legend(frameon=True, loc=\"upper right\")\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Histogram of p-values\n",
    "ax2.hist(p_values, bins=20, edgecolor=\"black\", alpha=0.7, color=\"#1f77b4\", density=True)\n",
    "ax2.axhline(1.0, color=\"red\", linestyle=\"--\", linewidth=2, alpha=0.5, label=\"Uniform distribution\")\n",
    "ax2.set_xlabel(\"P-value\")\n",
    "ax2.set_ylabel(\"Density\")\n",
    "ax2.set_title(\"Distribution of P-values\")\n",
    "ax2.legend(frameon=True, loc=\"upper right\")\n",
    "ax2.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423ee549",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "**Left panel:** P-values fluctuate around 0.5, as expected for well-specified model\n",
    "\n",
    "**Right panel:** P-values are roughly uniform (approximately equal density across range)\n",
    "\n",
    "**What this tells us:**\n",
    "- Observed data is consistent with model predictions\n",
    "- No systematic deviations (no clustering near 0 or 1)\n",
    "- Model appears well-calibrated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee77371",
   "metadata": {},
   "source": [
    "## Detecting Model Misspecification with P-Values\n",
    "\n",
    "Now let's see what happens when the model is misspecified during a period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d679e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create misspecified scenario: model predicts wrong location during middle period\n",
    "n_time = 100\n",
    "misfit_start = 40\n",
    "misfit_end = 60\n",
    "\n",
    "# State distribution: model's prediction\n",
    "model_means = 50 + 10 * np.sin(2 * np.pi * np.arange(n_time) / 50)\n",
    "state_dist_misspec = np.array([norm.pdf(position_bins, loc=m, scale=5.0) for m in model_means])\n",
    "state_dist_misspec = state_dist_misspec / state_dist_misspec.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Observed data: matches model except during misfit period\n",
    "rng = np.random.default_rng(42)\n",
    "observed_means = model_means.copy()\n",
    "observed_means[misfit_start:misfit_end] += 25  # Large offset during misfit period!\n",
    "\n",
    "observed_like_misspec = np.array(\n",
    "    [norm.pdf(position_bins, loc=m + rng.normal(0, 2), scale=3.0) for m in observed_means]\n",
    ")\n",
    "\n",
    "# Compute observed log predictive density\n",
    "observed_log_pred_misspec = log_predictive_density(\n",
    "    state_dist_misspec, likelihood=observed_like_misspec\n",
    ")\n",
    "\n",
    "# Create sampler (using correct model means, not observed)\n",
    "sampler_misspec = create_sampler(state_dist_misspec, model_means, position_bins)\n",
    "\n",
    "# Compute p-values\n",
    "p_values_misspec = predictive_pvalue(observed_log_pred_misspec, sampler_misspec, n_samples=1000)\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# P-values over time\n",
    "ax1.plot(\n",
    "    np.arange(n_time),\n",
    "    p_values_misspec,\n",
    "    linewidth=2,\n",
    "    marker=\"o\",\n",
    "    markersize=4,\n",
    "    alpha=0.7,\n",
    "    color=\"#1f77b4\",\n",
    ")\n",
    "ax1.axhline(0.5, color=\"green\", linestyle=\"--\", alpha=0.5, linewidth=2, label=\"Expected mean\")\n",
    "ax1.axhline(0.05, color=\"red\", linestyle=\"--\", alpha=0.5, linewidth=2, label=\"Extreme thresholds\")\n",
    "ax1.axhline(0.95, color=\"red\", linestyle=\"--\", alpha=0.5, linewidth=2)\n",
    "ax1.axvspan(misfit_start, misfit_end, alpha=0.2, color=\"red\", label=\"True misfit period\")\n",
    "ax1.set_ylabel(\"P-value\")\n",
    "ax1.set_title(\"P-values with Model Misspecification\")\n",
    "ax1.legend(frameon=True, loc=\"upper right\")\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Log predictive density over time\n",
    "ax2.plot(np.arange(n_time), observed_log_pred_misspec, linewidth=2, color=\"#ff7f0e\")\n",
    "ax2.axvspan(misfit_start, misfit_end, alpha=0.2, color=\"red\", label=\"Misfit period\")\n",
    "ax2.set_xlabel(\"Time\")\n",
    "ax2.set_ylabel(\"Log Predictive Density\")\n",
    "ax2.set_title(\"Log Predictive Density Over Time\")\n",
    "ax2.legend(frameon=True, loc=\"upper right\")\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"P-value statistics by period:\")\n",
    "print(f\"\\n{'Period':<15} {'Mean P-value':>12} {'% Extreme (<0.05 or >0.95)':>25}\")\n",
    "print(\"-\" * 55)\n",
    "good_pvals = p_values_misspec[\n",
    "    np.concatenate([np.arange(misfit_start), np.arange(misfit_end, n_time)])\n",
    "]\n",
    "bad_pvals = p_values_misspec[misfit_start:misfit_end]\n",
    "print(\n",
    "    f\"{'Good fit':<15} {np.mean(good_pvals):>12.3f} {((good_pvals < 0.05) | (good_pvals > 0.95)).sum() / len(good_pvals) * 100:>24.1f}%\"\n",
    ")\n",
    "print(\n",
    "    f\"{'Misfit':<15} {np.mean(bad_pvals):>12.3f} {((bad_pvals < 0.05) | (bad_pvals > 0.95)).sum() / len(bad_pvals) * 100:>24.1f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a40250c",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "**Key observations:**\n",
    "- **P-values drop dramatically** during misfit period (many near 0)\n",
    "- **Log predictive density decreases** during misfit (data is surprising)\n",
    "- **Good periods** have p-values scattered around 0.5\n",
    "- **Misfit periods** have extreme p-values (data very unlikely under model)\n",
    "\n",
    "**Why p-values near 0?**\n",
    "- Observed log predictive density is much lower than typical simulations\n",
    "- Most simulated datasets are more consistent with model than observed data\n",
    "- This indicates model fails to capture the data during that period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e174155",
   "metadata": {},
   "source": [
    "## Combining Multiple Diagnostics\n",
    "\n",
    "Let's bring everything together: KL divergence, HPD overlap, and predictive p-values provide complementary views of model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e851af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statespacecheck import hpd_overlap, kl_divergence\n",
    "\n",
    "# Compute all diagnostics for the misspecified case\n",
    "kl_div_misspec = kl_divergence(state_dist_misspec, observed_like_misspec)\n",
    "overlap_misspec = hpd_overlap(state_dist_misspec, observed_like_misspec, coverage=0.95)\n",
    "\n",
    "# Visualize all three together\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(14, 12), sharex=True)\n",
    "\n",
    "# KL divergence\n",
    "ax1.plot(np.arange(n_time), kl_div_misspec, linewidth=2.5, color=\"#1f77b4\")\n",
    "ax1.axhline(1.0, color=\"orange\", linestyle=\"--\", alpha=0.5, linewidth=2, label=\"High threshold\")\n",
    "ax1.axvspan(misfit_start, misfit_end, alpha=0.2, color=\"red\", label=\"Misfit period\")\n",
    "ax1.set_ylabel(\"KL Divergence\")\n",
    "ax1.set_title(\"Multiple Diagnostic Views of Model Fit\")\n",
    "ax1.legend(frameon=True, loc=\"upper left\")\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# HPD overlap\n",
    "ax2.plot(np.arange(n_time), overlap_misspec, linewidth=2.5, color=\"#ff7f0e\")\n",
    "ax2.axhline(0.3, color=\"orange\", linestyle=\"--\", alpha=0.5, linewidth=2, label=\"Low threshold\")\n",
    "ax2.axvspan(misfit_start, misfit_end, alpha=0.2, color=\"red\", label=\"Misfit period\")\n",
    "ax2.set_ylabel(\"HPD Overlap\")\n",
    "ax2.legend(frameon=True, loc=\"lower left\")\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# P-values\n",
    "ax3.plot(np.arange(n_time), p_values_misspec, linewidth=2.5, color=\"#2ca02c\")\n",
    "ax3.axhline(0.05, color=\"red\", linestyle=\"--\", alpha=0.5, linewidth=2, label=\"Extreme thresholds\")\n",
    "ax3.axhline(0.95, color=\"red\", linestyle=\"--\", alpha=0.5, linewidth=2)\n",
    "ax3.axhline(0.5, color=\"green\", linestyle=\"--\", alpha=0.5, linewidth=2, label=\"Expected value\")\n",
    "ax3.axvspan(misfit_start, misfit_end, alpha=0.2, color=\"red\", label=\"Misfit period\")\n",
    "ax3.set_xlabel(\"Time\")\n",
    "ax3.set_ylabel(\"P-value\")\n",
    "ax3.legend(frameon=True, loc=\"upper right\")\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c112b",
   "metadata": {},
   "source": [
    "### Complementary Information\n",
    "\n",
    "Each diagnostic provides a different perspective:\n",
    "\n",
    "**KL Divergence:**\n",
    "- Measures distribution disagreement\n",
    "- Spikes when state and likelihood concentrate mass differently\n",
    "- Sensitive to shape differences\n",
    "\n",
    "**HPD Overlap:**\n",
    "- Measures spatial consistency\n",
    "- Drops when high-density regions don't align\n",
    "- Intuitive spatial interpretation\n",
    "\n",
    "**P-values:**\n",
    "- Compares observed to expected under model\n",
    "- Detects when data is surprising/extreme\n",
    "- Requires simulation but provides calibrated interpretation\n",
    "\n",
    "**All three agree:** The misfit period is clearly problematic!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0ee9b1",
   "metadata": {},
   "source": [
    "## Practical Workflow for Your Data\n",
    "\n",
    "Here's a recommended workflow for applying these diagnostics to real state space models:\n",
    "\n",
    "### 1. Compute Basic Diagnostics\n",
    "```python\n",
    "kl_div = kl_divergence(state_dist, likelihood)\n",
    "overlap = hpd_overlap(state_dist, likelihood, coverage=0.95)\n",
    "```\n",
    "\n",
    "### 2. Visualize Over Time\n",
    "```python\n",
    "plt.plot(time, kl_div)\n",
    "plt.plot(time, overlap)\n",
    "```\n",
    "\n",
    "### 3. Flag Problematic Periods\n",
    "```python\n",
    "from statespacecheck import flag_extreme_kl, flag_low_overlap\n",
    "kl_flags = flag_extreme_kl(kl_div, threshold=1.0)\n",
    "overlap_flags = flag_low_overlap(overlap, threshold=0.3)\n",
    "```\n",
    "\n",
    "### 4. If Issues Detected, Compute P-values\n",
    "```python\n",
    "log_pred = log_predictive_density(state_dist, likelihood=likelihood)\n",
    "# Create sampler based on your model\n",
    "p_vals = predictive_pvalue(log_pred, sampler, n_samples=1000)\n",
    "```\n",
    "\n",
    "### 5. Interpret Results\n",
    "- Multiple metrics agree → Strong evidence of problem\n",
    "- Only one metric flags → Investigate further\n",
    "- P-values systematically extreme → Model misspecification\n",
    "- All metrics good → Model fits well!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e512124",
   "metadata": {},
   "source": [
    "## Summary: What We Learned\n",
    "\n",
    "**Core concepts:**\n",
    "- **Predictive density**: How likely is observed data under the model?\n",
    "- **Log-space**: Use `log_predictive_density()` for numerical stability\n",
    "- **P-values**: Compare observed to simulated data for calibrated interpretation\n",
    "\n",
    "**Key functions:**\n",
    "- `predictive_density()`: Compute p(y) = ∫ p(y|x) p(x) dx\n",
    "- `log_predictive_density()`: Compute in log-space for stability\n",
    "- `predictive_pvalue()`: Monte Carlo p-values via simulation\n",
    "\n",
    "**Practical insights:**\n",
    "- Predictive checks complement distribution comparison metrics\n",
    "- P-values near 0 or 1 indicate model problems\n",
    "- Log-space is essential for realistic applications\n",
    "- Multiple diagnostics provide robustness\n",
    "\n",
    "**Complete diagnostic toolkit:**\n",
    "1. **KL divergence**: Distribution disagreement\n",
    "2. **HPD overlap**: Spatial consistency\n",
    "3. **Predictive p-values**: Data plausibility\n",
    "4. **Time-resolved analysis**: Identify when/where models fail\n",
    "\n",
    "**Neuroscience applications:**\n",
    "- Validate neural decoding models\n",
    "- Compare different state space architectures\n",
    "- Identify behavioral epochs where models break down\n",
    "- Calibrate uncertainty estimates\n",
    "\n",
    "**You're now equipped** to thoroughly diagnose state space models!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9d5e19",
   "metadata": {},
   "source": [
    "## Exercises (Optional)\n",
    "\n",
    "1. What happens to p-values if you use too few simulation samples (e.g., n_samples=10)?\n",
    "2. Create a case where KL divergence is high but p-values are moderate. What does this tell you?\n",
    "3. How would you use predictive checks to compare two different model architectures?\n",
    "4. Can you detect the difference between systematic bias and random noise using these diagnostics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4718049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
